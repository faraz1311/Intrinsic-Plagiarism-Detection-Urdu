{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed8ec9a",
   "metadata": {},
   "source": [
    "### 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd1804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# datascience libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "# sklearn library\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16342be9",
   "metadata": {},
   "source": [
    "### 2. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374f3873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Names</th>\n",
       "      <th>Urdu Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>جنوبی ایشیا ئی کنفیڈریشن کی سازش، پردہ اُٹھتا ...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>چھ ہزار چار سو اسی گھنٹے\\r\\nمیں نے تنہائی کو ا...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ورزش کے پانچ حیران کن فوائد\\r\\nایسی خبریں آتی...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں‘...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>پھر یہ ہنگامہ اے خدا کیا ہے؟\\r\\nگستاخانہ فلم ک...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ماؤنٹ بلینک \\r\\nہم رات کے دس بجے شامونی پہنچے‘...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5436 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Names  \\\n",
       "0     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "1     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "2     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "3     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "4     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "...                                                 ...   \n",
       "5431  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5432  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5433  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5434  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5435  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "\n",
       "                                              Urdu Text            Label  \n",
       "0     وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...      Plagiarized  \n",
       "1     جنوبی ایشیا ئی کنفیڈریشن کی سازش، پردہ اُٹھتا ...  Non-Plagiarized  \n",
       "2     چھ ہزار چار سو اسی گھنٹے\\r\\nمیں نے تنہائی کو ا...  Non-Plagiarized  \n",
       "3     وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...      Plagiarized  \n",
       "4     ورزش کے پانچ حیران کن فوائد\\r\\nایسی خبریں آتی...      Plagiarized  \n",
       "...                                                 ...              ...  \n",
       "5431  وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...      Plagiarized  \n",
       "5432  اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں‘...      Plagiarized  \n",
       "5433  پھر یہ ہنگامہ اے خدا کیا ہے؟\\r\\nگستاخانہ فلم ک...  Non-Plagiarized  \n",
       "5434  ماؤنٹ بلینک \\r\\nہم رات کے دس بجے شامونی پہنچے‘...  Non-Plagiarized  \n",
       "5435  قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...      Plagiarized  \n",
       "\n",
       "[5436 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Para level Dataset\n",
    "data = load_files(r\"C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Dataset\\\\Para_level\", encoding='utf-8')\n",
    "\n",
    "# Convert the list of Text to a pandas DataFrame\n",
    "df_urdu_text = pd.DataFrame({\"Urdu Text\": data.data})\n",
    "\n",
    "# Convert the list of labels to a pandas DataFrame\n",
    "df_label=pd.DataFrame({\"Label\": data.target})\n",
    "df_label = df_label.replace([1], 'Plagiarized')\n",
    "df_label = df_label.replace([0], 'Non-Plagiarized')\n",
    "\n",
    "# Convert the list of file names to a pandas DataFrame\n",
    "file_names = pd.DataFrame({\"File Names\": data.filenames})\n",
    "\n",
    "df_para = pd.concat([file_names, df_urdu_text, df_label], axis=1)\n",
    "df_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f175be0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Names</th>\n",
       "      <th>Urdu Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>جنوبی ایشیا ئی کنفیڈریشن کی سازش، پردہ اُٹھتا ...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>چھ ہزار چار سو اسی گھنٹے\\r\\nمیں نے تنہائی کو ا...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>﻿شاہ محمود قریشی ، بابا ٹلّ اور مَیں!\\r\\n\\t\\t\\...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>پھر یہ ہنگامہ اے خدا کیا ہے؟\\r\\nگستاخانہ فلم ک...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں‘...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ماؤنٹ بلینک \\r\\nہم رات کے دس بجے شامونی پہنچے‘...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5436 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Names  \\\n",
       "0     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "1     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "2     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "3     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "4     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "...                                                 ...   \n",
       "5431  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5432  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5433  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5434  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5435  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "\n",
       "                                              Urdu Text            Label  \n",
       "0     جنوبی ایشیا ئی کنفیڈریشن کی سازش، پردہ اُٹھتا ...  Non-Plagiarized  \n",
       "1     وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...      Plagiarized  \n",
       "2     چھ ہزار چار سو اسی گھنٹے\\r\\nمیں نے تنہائی کو ا...  Non-Plagiarized  \n",
       "3     وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...      Plagiarized  \n",
       "4     ﻿شاہ محمود قریشی ، بابا ٹلّ اور مَیں!\\r\\n\\t\\t\\...  Non-Plagiarized  \n",
       "...                                                 ...              ...  \n",
       "5431  وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...      Plagiarized  \n",
       "5432  پھر یہ ہنگامہ اے خدا کیا ہے؟\\r\\nگستاخانہ فلم ک...  Non-Plagiarized  \n",
       "5433  اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں‘...      Plagiarized  \n",
       "5434  ماؤنٹ بلینک \\r\\nہم رات کے دس بجے شامونی پہنچے‘...  Non-Plagiarized  \n",
       "5435  قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...      Plagiarized  \n",
       "\n",
       "[5436 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearrange Para level Data in Balanced Way\n",
    "\n",
    "plagiarized_df_para = df_para[df_para['Label'] == 'Plagiarized'].reset_index(drop=True)\n",
    "non_plagiarized_df_para = df_para[df_para['Label'] == 'Non-Plagiarized'].reset_index(drop=True)\n",
    "\n",
    "dataset_para = pd.concat([plagiarized_df_para, non_plagiarized_df_para], keys=['Plagiarized', 'Non-plagiarized']).sort_index(level=1).reset_index(drop=True)\n",
    "dataset_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c62e7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Names</th>\n",
       "      <th>Urdu Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>اب دھرنوں سے آگے بڑھا جائے\\r\\nآپ سے پوچھا جا...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>القدس میں گزارے صدیوں پر محیط لمحے\\r\\nمقبوضہ ی...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ورزش کے پانچ حیران کن فوائد\\r\\nایسی خبریں آتی...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں،...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>کارپوریٹ رمضان اور نیا اسلام\\r\\nکرسمس امریکہ ا...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ایک صحافی اور ایک جنرل\\r\\n \\r\\nایک مرحوم امریک...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5436 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Names  \\\n",
       "0     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "1     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "2     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "3     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "4     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "...                                                 ...   \n",
       "5431  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5432  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5433  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5434  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5435  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "\n",
       "                                              Urdu Text            Label  \n",
       "0     وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...      Plagiarized  \n",
       "1     اب دھرنوں سے آگے بڑھا جائے\\r\\nآپ سے پوچھا جا...  Non-Plagiarized  \n",
       "2     القدس میں گزارے صدیوں پر محیط لمحے\\r\\nمقبوضہ ی...  Non-Plagiarized  \n",
       "3     وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...      Plagiarized  \n",
       "4     ورزش کے پانچ حیران کن فوائد\\r\\nایسی خبریں آتی...      Plagiarized  \n",
       "...                                                 ...              ...  \n",
       "5431  وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...      Plagiarized  \n",
       "5432  اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں،...      Plagiarized  \n",
       "5433  کارپوریٹ رمضان اور نیا اسلام\\r\\nکرسمس امریکہ ا...  Non-Plagiarized  \n",
       "5434  ایک صحافی اور ایک جنرل\\r\\n \\r\\nایک مرحوم امریک...  Non-Plagiarized  \n",
       "5435  قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...      Plagiarized  \n",
       "\n",
       "[5436 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Sentence Level Dataset\n",
    "data = load_files(r\"C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Dataset\\\\Sentence_level\", encoding='utf-8')\n",
    "\n",
    "# Convert the list of Text to a pandas DataFrame\n",
    "df_urdu_text = pd.DataFrame({\"Urdu Text\": data.data})\n",
    "\n",
    "# Convert the list of labels to a pandas DataFrame\n",
    "df_label=pd.DataFrame({\"Label\": data.target})\n",
    "df_label = df_label.replace([1], 'Plagiarized')\n",
    "df_label = df_label.replace([0], 'Non-Plagiarized')\n",
    "\n",
    "# Convert the list of file names to a pandas DataFrame\n",
    "file_names = pd.DataFrame({\"File Names\": data.filenames})\n",
    "\n",
    "df_sen = pd.concat([file_names, df_urdu_text, df_label], axis=1)\n",
    "df_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "917ca2c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Names</th>\n",
       "      <th>Urdu Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>اب دھرنوں سے آگے بڑھا جائے\\r\\nآپ سے پوچھا جا...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>القدس میں گزارے صدیوں پر محیط لمحے\\r\\nمقبوضہ ی...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ایکیو پریشر\\r\\nکچھ عرصہ قبل کی بات ہے کہ مجھے ...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>کارپوریٹ رمضان اور نیا اسلام\\r\\nکرسمس امریکہ ا...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں،...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ایک صحافی اور ایک جنرل\\r\\n \\r\\nایک مرحوم امریک...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5436 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Names  \\\n",
       "0     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "1     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "2     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "3     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "4     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "...                                                 ...   \n",
       "5431  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5432  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5433  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5434  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "5435  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "\n",
       "                                              Urdu Text            Label  \n",
       "0     اب دھرنوں سے آگے بڑھا جائے\\r\\nآپ سے پوچھا جا...  Non-Plagiarized  \n",
       "1     وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...      Plagiarized  \n",
       "2     القدس میں گزارے صدیوں پر محیط لمحے\\r\\nمقبوضہ ی...  Non-Plagiarized  \n",
       "3     وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...      Plagiarized  \n",
       "4     ایکیو پریشر\\r\\nکچھ عرصہ قبل کی بات ہے کہ مجھے ...  Non-Plagiarized  \n",
       "...                                                 ...              ...  \n",
       "5431  وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...      Plagiarized  \n",
       "5432  کارپوریٹ رمضان اور نیا اسلام\\r\\nکرسمس امریکہ ا...  Non-Plagiarized  \n",
       "5433  اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں،...      Plagiarized  \n",
       "5434  ایک صحافی اور ایک جنرل\\r\\n \\r\\nایک مرحوم امریک...  Non-Plagiarized  \n",
       "5435  قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...      Plagiarized  \n",
       "\n",
       "[5436 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rearrange sentence level Data in Balanced Way\n",
    "\n",
    "plagiarized_df_sen = df_sen[df_sen['Label'] == 'Plagiarized'].reset_index(drop=True)\n",
    "non_plagiarized_df_sen = df_sen[df_sen['Label'] == 'Non-Plagiarized'].reset_index(drop=True)\n",
    "\n",
    "dataset_sen = pd.concat([plagiarized_df_sen, non_plagiarized_df_sen], keys=['Plagiarized', 'Non-plagiarized']).sort_index(level=1).reset_index(drop=True)\n",
    "dataset_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee5b052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Names</th>\n",
       "      <th>Urdu Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>اب دھرنوں سے آگے بڑھا جائے\\r\\nآپ سے پوچھا جا...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>القدس میں گزارے صدیوں پر محیط لمحے\\r\\nمقبوضہ ی...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ایکیو پریشر\\r\\nکچھ عرصہ قبل کی بات ہے کہ مجھے ...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10867</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>پھر یہ ہنگامہ اے خدا کیا ہے؟\\r\\nگستاخانہ فلم ک...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں‘...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>ماؤنٹ بلینک \\r\\nہم رات کے دس بجے شامونی پہنچے‘...</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10872 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              File Names  \\\n",
       "0      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "1      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "2      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "3      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "4      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "...                                                  ...   \n",
       "10867  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "10868  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "10869  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "10870  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "10871  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...   \n",
       "\n",
       "                                               Urdu Text            Label  \n",
       "0      اب دھرنوں سے آگے بڑھا جائے\\r\\nآپ سے پوچھا جا...  Non-Plagiarized  \n",
       "1      وقت کی قدر شناسی، کامیابی کا راز\\r\\nکائنات کے ...      Plagiarized  \n",
       "2      القدس میں گزارے صدیوں پر محیط لمحے\\r\\nمقبوضہ ی...  Non-Plagiarized  \n",
       "3      وقت کی پابندی کو عادت بنانا کیسے ممکن؟\\r\\nوقت ...      Plagiarized  \n",
       "4      ایکیو پریشر\\r\\nکچھ عرصہ قبل کی بات ہے کہ مجھے ...  Non-Plagiarized  \n",
       "...                                                  ...              ...  \n",
       "10867  وقت کی پابندی\\r\\nاللہ تعالیٰ نے اپنی قدرتِ کام...      Plagiarized  \n",
       "10868  پھر یہ ہنگامہ اے خدا کیا ہے؟\\r\\nگستاخانہ فلم ک...  Non-Plagiarized  \n",
       "10869  اسلام میں تعلیم نسوان پر تاکید\\r\\nتعلیم نسواں‘...      Plagiarized  \n",
       "10870  ماؤنٹ بلینک \\r\\nہم رات کے دس بجے شامونی پہنچے‘...  Non-Plagiarized  \n",
       "10871  قائداعظم پر ایک مضمون\\r\\nپونجا جناح کا اصل وطن...      Plagiarized  \n",
       "\n",
       "[10872 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine Sentence and Para Level Dataset\n",
    "\n",
    "dataset_complete = pd.concat([dataset_sen, dataset_para], axis=0).reset_index(drop=True)\n",
    "dataset_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16f9fb",
   "metadata": {},
   "source": [
    "### 3. Extract All Stylometry Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af18055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to Extract All Stylometry Features\n",
    "\n",
    "def calculate_text_features(text):\n",
    "    \n",
    "    # 1. Word-Level stylometry features (10)\n",
    "    # 2. Character-Level stylometry features (16)\n",
    "    # 3. Sentence-Level stylometry features (7)\n",
    "    # 4. Para-Level stylometry features (8)\n",
    "    # 5. Document-Level stylometry features (1)\n",
    "    # 6. Textual Entropy stylometry features (1)\n",
    "    \n",
    "    #******** 1. Word-Level stylometry features (10) ********\n",
    "    \n",
    "    ##1 total number of words\n",
    "    words = text.split()\n",
    "    total_words = len(words)\n",
    " \n",
    "    ##2 total number of lines\n",
    "    lines = text.split('\\n')\n",
    "    total_lines = len(lines)\n",
    "\n",
    "    ##3 total number of empty lines\n",
    "    empty_line_count = sum(1 for line in lines if not line.strip())\n",
    "\n",
    "    ##4 average words length\n",
    "    total_word_length = sum(len(word) for word in words)\n",
    "    average_word_length = total_word_length / len(words) if len(words) > 0 else 0\n",
    "    \n",
    "    ##5 ratio of words with length 3\n",
    "    len_3=len([word for word in words if len(word) == 3])\n",
    "    ratio_of_3 = round(len_3/total_words if total_words > 0 else 0,2)        \n",
    "\n",
    "    ##6 ratio of words with length 4\n",
    "    len_4=len([word for word in words if len(word) == 4])\n",
    "    ratio_of_4 = round(len_4/total_words if total_words > 0 else 0,2)   \n",
    "    \n",
    "    ##7 ratio of Long words(>=8)\n",
    "    long_words = len([word for word in words if len(word) >= 8])\n",
    "    ratio_of_long_words = round(long_words/total_words if total_words > 0 else 0,2)\n",
    "\n",
    "    ##8 total number of unique words\n",
    "    unique_words = set(words)\n",
    "    total_unique_words = len(unique_words)    \n",
    "     \n",
    "    ##9 Total Punctuations count,No. of Punctuations, Frequency of each Punctuation\n",
    "    # Define the list of punctuations you want to count\n",
    "    punctuations = [\"؟\", \"!\", \"?\", \"...\", \"؛\", \".\", \"،\", \")\", \"(\", \"۔\"]\n",
    "    characters = re.findall(r'.', text)\n",
    "    punctuation_freq = {}\n",
    "    punctuation_count = 0\n",
    "    for char in characters:\n",
    "        if char in punctuations:\n",
    "            punctuation_freq[char] = punctuation_freq.get(char, 0) + 1\n",
    "            punctuation_count += 1\n",
    "          \n",
    "    ##10 Punctuation Count / Total Words\n",
    "    punctuation_ratio = punctuation_count/total_words if total_words > 0 else 0\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #******** 2. Character-Level stylometry features (16) ********\n",
    "    \n",
    "    ##1 Total commas\n",
    "    comma_count = text.count('،')    \n",
    "\n",
    "    ##2 Total dashes\n",
    "    dashes_count = text.count('۔')\n",
    "    \n",
    "    ##3 Total open_parentheses\n",
    "    open_parentheses_count = text.count('(')\n",
    "    \n",
    "    ##4 Total close_parentheses\n",
    "    close_parentheses_count = text.count(')')\n",
    "\n",
    "    ##5 Total semicolons\n",
    "    semicolons_count = text.count('؛')\n",
    "\n",
    "    ##6 Total white spaces\n",
    "    white_spaces_count = text.count(' ')\n",
    "\n",
    "    ##7 Total question_marks\n",
    "    question_marks_count = text.count('؟')\n",
    "\n",
    "    ##8 Total exclamation marks\n",
    "    exclamation_marks_count = text.count('!')\n",
    "\n",
    "    ##9 Total ampersands\n",
    "    ampersands_count = text.count('&')\n",
    "\n",
    "    ##10 Total percentage signs\n",
    "    percentage_signs = text.count('%')\n",
    "\n",
    "    ##11 Total single quotes\n",
    "    number_of_left_single_quotes = text.count('‘')\n",
    "    number_of_right_single_quotes = text.count('’')\n",
    "    number_of_single_quotes = number_of_left_single_quotes + number_of_right_single_quotes\n",
    "\n",
    "    ##12 Total double quotes\n",
    "    number_of_left_double_quotes = text.count('“')\n",
    "    number_of_right_double_quotes = text.count('”')\n",
    "    number_of_double_quotes = number_of_left_double_quotes + number_of_right_double_quotes\n",
    "\n",
    "    ##13 Total colons\n",
    "    colons_count = text.count(':')\n",
    "    \n",
    "    ##14 Total characters without spaces \n",
    "    number_of_characters_without_spaces = len(text.replace(\" \",\"\"))\n",
    "\n",
    "    ##15 Total digits\n",
    "    digit_count = 0\n",
    "    for character in text:\n",
    "        if character.isdigit():\n",
    "            digit_count += 1\n",
    "\n",
    "    ##16 Total brackets\n",
    "    no_of_all_brackets = 0\n",
    "    for b in text:\n",
    "        if b == '(' or b == '{' or b == '[' or b == ')' or b == '}' or b == ']':\n",
    "            no_of_all_brackets = no_of_all_brackets + 1   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #******** 3. Sentence-Level stylometry features (7) ********\n",
    "    \n",
    "    ##1 total number of sentences\n",
    "    sentences = re.split(r'(?<=[.۔؟!؛])\\s+', text)\n",
    "    total_sentences = len(sentences)\n",
    "    if len(text) != 0 and total_sentences == 0:\n",
    "        total_sentences += 1\n",
    "\n",
    "    ##2 average no. of words per sentence\n",
    "    sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "    average_sentence_length_in_words = sum(sentence_lengths) / total_sentences if total_sentences > 0 else 0\n",
    "    \n",
    "    ##3 average no. of Characters per sentence or average sentence length\n",
    "    total_chars = sum(len(sentence) for sentence in sentences)\n",
    "    average_sentence_length_in_char = total_chars / total_sentences if total_sentences > 0 else 0\n",
    "    \n",
    "    ##4 min sentence length\n",
    "    min_sentence_length = min(len(sentence.split()) for sentence in sentences)\n",
    "    \n",
    "    ##5 max sentence length\n",
    "    max_sentence_length = max(len(sentence.split()) for sentence in sentences)\n",
    "    \n",
    "    ##6 average no. of White Spaces per sentence\n",
    "    average_spaces_per_sentence = sum(sentence.count(' ') for sentence in sentences) / len(sentences) if sentences else 0    \n",
    "    \n",
    "    ##7 percentage of question sentences\n",
    "    total_question_sentences = sum(1 for sentence in sentences if sentence.endswith(\"؟\"))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #******** 4. Para-Level stylometry features (8) ********    \n",
    "    \n",
    "    ##1 total number of paragraphs\n",
    "    # Split the text into paragraphs based on one or more empty lines\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', text)\n",
    "    total_paragraphs = len(paragraphs)\n",
    "    \n",
    "    ##2 average paragraph length\n",
    "    total_length = sum(len(paragraph) for paragraph in paragraphs)\n",
    "    average_paragraph_length = total_length / total_paragraphs if total_paragraphs > 0 else 0\n",
    "    \n",
    "    ##3 min paragraph length\n",
    "    min_paragraph_length = min(len(p) for p in paragraphs)\n",
    "    \n",
    "    ##4 max paragraph length\n",
    "    max_paragraph_length = max(len(p) for p in paragraphs)\n",
    "    \n",
    "    ##5 average no. of words per paragraph\n",
    "    average_words_per_paragraph = sum(len(paragraph.split()) for paragraph in paragraphs) / len(paragraphs)\n",
    "    \n",
    "    ##6 average no. of Sentences per paragraph\n",
    "    sentences_per_paragraph = [len(re.findall(r'[\\w۔]+', paragraph)) for paragraph in paragraphs]\n",
    "    average_sentences_per_paragraph = sum(sentences_per_paragraph) / total_paragraphs if total_paragraphs > 0 else 0\n",
    "\n",
    "    ##7 average no. of Punctuations per paragraph\n",
    "    punctuation_ratio_per_para = punctuation_count/total_words if total_words > 0 else 0\n",
    "    \n",
    "    ##8 averageno. of Question Marks per paragraph\n",
    "    average_question_marks_per_paragraph = question_marks_count / total_paragraphs if total_paragraphs > 0 else 0\n",
    "    \n",
    "    \n",
    "    \n",
    "      \n",
    "    #******** 5. Document-Level stylometry features (1) ********\n",
    "     \n",
    "    ##1 Lexical Density\n",
    "    # Create a list of unique words (content words)\n",
    "    unique_words = list(set(words))\n",
    "\n",
    "    # Calculate the number of content words in the text\n",
    "    content_word_count = len(unique_words)\n",
    "\n",
    "    # Calculate lexical density (content word count / total words)\n",
    "    lexical_density = content_word_count / total_words if total_words > 0 else 0\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #******** 6. Textual Entropy stylometry features (1) ********\n",
    "    \n",
    "    ##1 Calculate textual entropy    \n",
    "    # Calculate the frequency of each character\n",
    "    char_freq = Counter(text)\n",
    "    total_chars = len(text)\n",
    "    entropy = -sum((count / total_chars) * math.log(count / total_chars, 2) for count in char_freq.values())\n",
    "    \n",
    "    return total_words, total_lines, empty_line_count, average_word_length, ratio_of_3, ratio_of_4, ratio_of_long_words, total_unique_words, punctuation_count, punctuation_ratio, comma_count, dashes_count, open_parentheses_count, close_parentheses_count, semicolons_count, white_spaces_count, question_marks_count, exclamation_marks_count, ampersands_count, percentage_signs, number_of_single_quotes, number_of_double_quotes, colons_count, number_of_characters_without_spaces, digit_count, no_of_all_brackets, total_sentences, average_sentence_length_in_words, average_sentence_length_in_char, min_sentence_length, max_sentence_length, average_spaces_per_sentence, total_question_sentences, total_paragraphs, average_paragraph_length, min_paragraph_length, max_paragraph_length, average_words_per_paragraph, average_sentences_per_paragraph, punctuation_ratio_per_para, average_question_marks_per_paragraph, lexical_density, entropy           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc233e",
   "metadata": {},
   "source": [
    "##### 3.1 Extract Stylometry Features at granularity level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a204b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Extract Stylometry Features of Para-Level Dataset\n",
    "\n",
    "# list of all extracted features\n",
    "stylometry_features_list_para_level = []\n",
    "\n",
    "for row in dataset_para['Urdu Text']:\n",
    "           \n",
    "    ## resolving single \\n and double \\n problem\n",
    "    # Replace '\\n\\n' with a space to join paragraphs\n",
    "    text = row.replace('\\n\\n', '%%')\n",
    "\n",
    "    # Replace '\\n' with a space to join paragraphs\n",
    "    text = text.replace('\\n', '%%')\n",
    "\n",
    "    # Split the text into paragraphs based on the space character\n",
    "    paragraphs = text.split('%%')\n",
    "\n",
    "    # Remove any empty spaces\n",
    "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "\n",
    "    # paragraphs which are large but dont endswith(-), - sign inserted at the end of those paragraphs\n",
    "    # removing paragraphs which are small and dont endswith('-') and small bullet points\n",
    "\n",
    "    paragraph_list = []\n",
    "    for p in paragraphs:\n",
    "        if len(p)<80: # small paragraphs excluded \n",
    "            continue\n",
    "        elif (not p.endswith('۔') and not p.endswith('.') and not p.endswith('؟') and not p.endswith('؛')) and len(p)>150:\n",
    "            paragraph_list.append(p + '۔') # large paragraphs without ending on -, handeled here\n",
    "        elif (p.endswith('۔') or p.endswith('.') or p.endswith('؟') or p.endswith('؛')):\n",
    "            paragraph_list.append(p) #paragraphs added to list\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    text = '\\n\\n'.join(paragraph_list)  \n",
    "\n",
    "    # Write the results to list\n",
    "    stylometry_features_list_para_level.append(calculate_text_features(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f9ba4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stylometry Features of Para-Level Dataset :\n",
      "=============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Names</th>\n",
       "      <th>total_words</th>\n",
       "      <th>total_lines</th>\n",
       "      <th>empty_line_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>ratio_of_3</th>\n",
       "      <th>ratio_of_4</th>\n",
       "      <th>ratio_of_long_words</th>\n",
       "      <th>total_unique_words</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>...</th>\n",
       "      <th>average_paragraph_length</th>\n",
       "      <th>min_paragraph_length</th>\n",
       "      <th>max_paragraph_length</th>\n",
       "      <th>average_words_per_paragraph</th>\n",
       "      <th>average_sentences_per_paragraph</th>\n",
       "      <th>punctuation_ratio_per_para</th>\n",
       "      <th>average_question_marks_per_paragraph</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>entropy</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1610</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>3.690062</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.02</td>\n",
       "      <td>753</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>579.846154</td>\n",
       "      <td>396</td>\n",
       "      <td>796</td>\n",
       "      <td>123.846154</td>\n",
       "      <td>127.538462</td>\n",
       "      <td>0.054037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.467702</td>\n",
       "      <td>4.427147</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1253</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3.492418</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>544</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>624.444444</td>\n",
       "      <td>148</td>\n",
       "      <td>1777</td>\n",
       "      <td>139.222222</td>\n",
       "      <td>139.888889</td>\n",
       "      <td>0.067039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434158</td>\n",
       "      <td>4.375206</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1470</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>3.560544</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>556</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>196</td>\n",
       "      <td>802</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>106.714286</td>\n",
       "      <td>0.059864</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.378231</td>\n",
       "      <td>4.411654</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>862</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>3.474478</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>377</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>256.133333</td>\n",
       "      <td>152</td>\n",
       "      <td>718</td>\n",
       "      <td>57.466667</td>\n",
       "      <td>57.533333</td>\n",
       "      <td>0.051044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437355</td>\n",
       "      <td>4.387582</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1261</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.596352</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>508</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>5833.000000</td>\n",
       "      <td>5833</td>\n",
       "      <td>5833</td>\n",
       "      <td>1261.000000</td>\n",
       "      <td>1341.000000</td>\n",
       "      <td>0.088025</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.402855</td>\n",
       "      <td>4.557093</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1529</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>3.578810</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>661</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>635.454545</td>\n",
       "      <td>162</td>\n",
       "      <td>1022</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>139.272727</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432309</td>\n",
       "      <td>4.383694</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1556</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>3.475578</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>691</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>534.692308</td>\n",
       "      <td>109</td>\n",
       "      <td>772</td>\n",
       "      <td>119.692308</td>\n",
       "      <td>120.615385</td>\n",
       "      <td>0.073907</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>0.444087</td>\n",
       "      <td>4.386175</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>814</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3.523342</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>388</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>224</td>\n",
       "      <td>1728</td>\n",
       "      <td>116.285714</td>\n",
       "      <td>117.714286</td>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476658</td>\n",
       "      <td>4.431409</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1827</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>3.550082</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>631</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>638.769231</td>\n",
       "      <td>318</td>\n",
       "      <td>880</td>\n",
       "      <td>140.538462</td>\n",
       "      <td>140.307692</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345375</td>\n",
       "      <td>4.423068</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>616</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3.759740</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>326</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>324.888889</td>\n",
       "      <td>174</td>\n",
       "      <td>635</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529221</td>\n",
       "      <td>4.459937</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5436 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Names  total_words  \\\n",
       "0     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1610   \n",
       "1     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1253   \n",
       "2     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1470   \n",
       "3     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          862   \n",
       "4     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1261   \n",
       "...                                                 ...          ...   \n",
       "5431  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1529   \n",
       "5432  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1556   \n",
       "5433  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          814   \n",
       "5434  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1827   \n",
       "5435  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          616   \n",
       "\n",
       "      total_lines  empty_line_count  average_word_length  ratio_of_3  \\\n",
       "0              25                12             3.690062        0.24   \n",
       "1              17                 8             3.492418        0.26   \n",
       "2              27                13             3.560544        0.25   \n",
       "3              29                14             3.474478        0.26   \n",
       "4               1                 0             3.596352        0.24   \n",
       "...           ...               ...                  ...         ...   \n",
       "5431           21                10             3.578810        0.25   \n",
       "5432           25                12             3.475578        0.23   \n",
       "5433           13                 6             3.523342        0.23   \n",
       "5434           25                12             3.550082        0.26   \n",
       "5435           17                 8             3.759740        0.25   \n",
       "\n",
       "      ratio_of_4  ratio_of_long_words  total_unique_words  punctuation_count  \\\n",
       "0           0.22                 0.02                 753                 87   \n",
       "1           0.23                 0.01                 544                 84   \n",
       "2           0.24                 0.01                 556                 88   \n",
       "3           0.23                 0.01                 377                 44   \n",
       "4           0.23                 0.02                 508                111   \n",
       "...          ...                  ...                 ...                ...   \n",
       "5431        0.21                 0.01                 661                 64   \n",
       "5432        0.25                 0.01                 691                115   \n",
       "5433        0.21                 0.02                 388                 73   \n",
       "5434        0.24                 0.01                 631                 14   \n",
       "5435        0.17                 0.05                 326                 42   \n",
       "\n",
       "      ...  average_paragraph_length  min_paragraph_length  \\\n",
       "0     ...                579.846154                   396   \n",
       "1     ...                624.444444                   148   \n",
       "2     ...                478.000000                   196   \n",
       "3     ...                256.133333                   152   \n",
       "4     ...               5833.000000                  5833   \n",
       "...   ...                       ...                   ...   \n",
       "5431  ...                635.454545                   162   \n",
       "5432  ...                534.692308                   109   \n",
       "5433  ...                525.000000                   224   \n",
       "5434  ...                638.769231                   318   \n",
       "5435  ...                324.888889                   174   \n",
       "\n",
       "      max_paragraph_length  average_words_per_paragraph  \\\n",
       "0                      796                   123.846154   \n",
       "1                     1777                   139.222222   \n",
       "2                      802                   105.000000   \n",
       "3                      718                    57.466667   \n",
       "4                     5833                  1261.000000   \n",
       "...                    ...                          ...   \n",
       "5431                  1022                   139.000000   \n",
       "5432                   772                   119.692308   \n",
       "5433                  1728                   116.285714   \n",
       "5434                   880                   140.538462   \n",
       "5435                   635                    68.444444   \n",
       "\n",
       "      average_sentences_per_paragraph  punctuation_ratio_per_para  \\\n",
       "0                          127.538462                    0.054037   \n",
       "1                          139.888889                    0.067039   \n",
       "2                          106.714286                    0.059864   \n",
       "3                           57.533333                    0.051044   \n",
       "4                         1341.000000                    0.088025   \n",
       "...                               ...                         ...   \n",
       "5431                       139.272727                    0.041857   \n",
       "5432                       120.615385                    0.073907   \n",
       "5433                       117.714286                    0.089681   \n",
       "5434                       140.307692                    0.007663   \n",
       "5435                        68.444444                    0.068182   \n",
       "\n",
       "      average_question_marks_per_paragraph  lexical_density   entropy  \\\n",
       "0                                 0.000000         0.467702  4.427147   \n",
       "1                                 0.000000         0.434158  4.375206   \n",
       "2                                 0.428571         0.378231  4.411654   \n",
       "3                                 0.000000         0.437355  4.387582   \n",
       "4                                15.000000         0.402855  4.557093   \n",
       "...                                    ...              ...       ...   \n",
       "5431                              0.000000         0.432309  4.383694   \n",
       "5432                              1.384615         0.444087  4.386175   \n",
       "5433                              0.000000         0.476658  4.431409   \n",
       "5434                              0.000000         0.345375  4.423068   \n",
       "5435                              0.000000         0.529221  4.459937   \n",
       "\n",
       "                Label  \n",
       "0     Non-Plagiarized  \n",
       "1         Plagiarized  \n",
       "2     Non-Plagiarized  \n",
       "3         Plagiarized  \n",
       "4     Non-Plagiarized  \n",
       "...               ...  \n",
       "5431      Plagiarized  \n",
       "5432  Non-Plagiarized  \n",
       "5433      Plagiarized  \n",
       "5434  Non-Plagiarized  \n",
       "5435      Plagiarized  \n",
       "\n",
       "[5436 rows x 45 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store para-level dataset into .csv File and Dataframe\n",
    "\n",
    "# Convert Stylometry Features list into Dataframe    \n",
    "para_stylometry_features = pd.DataFrame(stylometry_features_list_para_level)\n",
    "\n",
    "# adding header row accoring to the extracted stylometry feature\n",
    "para_stylometry_features.columns = ['total_words', 'total_lines', 'empty_line_count', 'average_word_length', 'ratio_of_3', 'ratio_of_4', 'ratio_of_long_words', 'total_unique_words', 'punctuation_count', 'punctuation_ratio', 'comma_count', 'dashes_count', 'open_parentheses_count', 'close_parentheses_count', 'semicolons_count', 'white_spaces_count', 'question_marks_count', 'exclamation_marks_count', 'ampersands_count', 'percentage_signs', 'number_of_single_quotes', 'number_of_double_quotes', 'colons_count', 'number_of_characters_without_spaces', 'digit_count', 'no_of_all_brackets', 'total_sentences', 'average_sentence_length_in_words', 'average_sentence_length_in_char', 'min_sentence_length', 'max_sentence_length', 'average_spaces_per_sentence', 'total_question_sentences', 'total_paragraphs', 'average_paragraph_length', 'min_paragraph_length', 'max_paragraph_length', 'average_words_per_paragraph', 'average_sentences_per_paragraph', 'punctuation_ratio_per_para', 'average_question_marks_per_paragraph', 'lexical_density', 'entropy']\n",
    "\n",
    "# Combine the Input Feature Vectors and Output Label\n",
    "para_stylometry_features = pd.concat([dataset_para[['File Names']], para_stylometry_features, dataset_para[['Label']]], axis=1)\n",
    "\n",
    "# store results into .csv file\n",
    "para_stylometry_features.to_csv(r'para_stylometry_features.csv', index = False, header=True)\n",
    "\n",
    "# Display all Stylometric Features of Dataset\n",
    "print(\"\\nStylometry Features of Para-Level Dataset :\")\n",
    "print(\"=============================================\\n\")\n",
    "para_stylometry_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec9ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- Extract Stylometry Features of Sentence-Level Dataset\n",
    "\n",
    "# list of all extracted features\n",
    "stylometry_features_list_sentence_level = []\n",
    "\n",
    "for row in dataset_sen['Urdu Text']:\n",
    "           \n",
    "    ## resolving single \\n and double \\n problem\n",
    "    # Replace '\\n\\n' with a space to join paragraphs\n",
    "    text = row.replace('\\n\\n', '%%')\n",
    "\n",
    "    # Replace '\\n' with a space to join paragraphs\n",
    "    text = text.replace('\\n', '%%')\n",
    "\n",
    "    # Split the text into paragraphs based on the space character\n",
    "    paragraphs = text.split('%%')\n",
    "\n",
    "    # Remove any empty spaces\n",
    "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "\n",
    "    # paragraphs which are large but dont endswith(-), - sign inserted at the end of those paragraphs\n",
    "    # removing paragraphs which are small and dont endswith('-') and small bullet points\n",
    "\n",
    "    paragraph_list = []\n",
    "    for p in paragraphs:\n",
    "        if len(p)<80: # small paragraphs excluded \n",
    "            continue\n",
    "        elif (not p.endswith('۔') and not p.endswith('.') and not p.endswith('؟') and not p.endswith('؛')) and len(p)>150:\n",
    "            paragraph_list.append(p + '۔') # large paragraphs without ending on -, handeled here\n",
    "        elif (p.endswith('۔') or p.endswith('.') or p.endswith('؟') or p.endswith('؛')):\n",
    "            paragraph_list.append(p) #paragraphs added to list\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    text = '\\n\\n'.join(paragraph_list)  \n",
    "\n",
    "    # Write the results to list\n",
    "    stylometry_features_list_sentence_level.append(calculate_text_features(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d9ffbe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stylometry Features of Sen-Level Dataset :\n",
      "============================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Names</th>\n",
       "      <th>total_words</th>\n",
       "      <th>total_lines</th>\n",
       "      <th>empty_line_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>ratio_of_3</th>\n",
       "      <th>ratio_of_4</th>\n",
       "      <th>ratio_of_long_words</th>\n",
       "      <th>total_unique_words</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>...</th>\n",
       "      <th>average_paragraph_length</th>\n",
       "      <th>min_paragraph_length</th>\n",
       "      <th>max_paragraph_length</th>\n",
       "      <th>average_words_per_paragraph</th>\n",
       "      <th>average_sentences_per_paragraph</th>\n",
       "      <th>punctuation_ratio_per_para</th>\n",
       "      <th>average_question_marks_per_paragraph</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>entropy</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1147</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>3.682650</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.02</td>\n",
       "      <td>531</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>357.133333</td>\n",
       "      <td>244</td>\n",
       "      <td>480</td>\n",
       "      <td>76.466667</td>\n",
       "      <td>78.266667</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.462947</td>\n",
       "      <td>4.437910</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1166</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3.484563</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>526</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>316</td>\n",
       "      <td>1769</td>\n",
       "      <td>166.571429</td>\n",
       "      <td>167.285714</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451115</td>\n",
       "      <td>4.375210</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1261</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3.762887</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.02</td>\n",
       "      <td>571</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>475</td>\n",
       "      <td>1710</td>\n",
       "      <td>210.166667</td>\n",
       "      <td>213.833333</td>\n",
       "      <td>0.079302</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.452815</td>\n",
       "      <td>4.452497</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>612</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>3.508170</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>266</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>211.230769</td>\n",
       "      <td>162</td>\n",
       "      <td>305</td>\n",
       "      <td>47.076923</td>\n",
       "      <td>47.153846</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434641</td>\n",
       "      <td>4.385417</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1143</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>3.381452</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>442</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>454.272727</td>\n",
       "      <td>270</td>\n",
       "      <td>694</td>\n",
       "      <td>103.909091</td>\n",
       "      <td>104.090909</td>\n",
       "      <td>0.042870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386702</td>\n",
       "      <td>4.331698</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1522</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>3.578844</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>662</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>695.900000</td>\n",
       "      <td>265</td>\n",
       "      <td>1153</td>\n",
       "      <td>152.200000</td>\n",
       "      <td>152.600000</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434954</td>\n",
       "      <td>4.389411</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5432</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.524330</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>430</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>4563.000000</td>\n",
       "      <td>4563</td>\n",
       "      <td>4563</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>0.051639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.427011</td>\n",
       "      <td>4.282201</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>799</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3.508135</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>381</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>599.333333</td>\n",
       "      <td>253</td>\n",
       "      <td>1728</td>\n",
       "      <td>133.166667</td>\n",
       "      <td>134.333333</td>\n",
       "      <td>0.086358</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476846</td>\n",
       "      <td>4.422597</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1256</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>3.661624</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>561</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>730.875000</td>\n",
       "      <td>257</td>\n",
       "      <td>1817</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>159.250000</td>\n",
       "      <td>0.069268</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.446656</td>\n",
       "      <td>4.497136</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>715</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>368</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>374.666667</td>\n",
       "      <td>174</td>\n",
       "      <td>766</td>\n",
       "      <td>79.444444</td>\n",
       "      <td>79.222222</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.514685</td>\n",
       "      <td>4.451969</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5436 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             File Names  total_words  \\\n",
       "0     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1147   \n",
       "1     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1166   \n",
       "2     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1261   \n",
       "3     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          612   \n",
       "4     C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1143   \n",
       "...                                                 ...          ...   \n",
       "5431  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1522   \n",
       "5432  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1007   \n",
       "5433  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          799   \n",
       "5434  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1256   \n",
       "5435  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          715   \n",
       "\n",
       "      total_lines  empty_line_count  average_word_length  ratio_of_3  \\\n",
       "0              29                14             3.682650        0.24   \n",
       "1              13                 6             3.484563        0.26   \n",
       "2              11                 5             3.762887        0.23   \n",
       "3              25                12             3.508170        0.25   \n",
       "4              21                10             3.381452        0.27   \n",
       "...           ...               ...                  ...         ...   \n",
       "5431           19                 9             3.578844        0.25   \n",
       "5432            1                 0             3.524330        0.26   \n",
       "5433           11                 5             3.508135        0.24   \n",
       "5434           15                 7             3.661624        0.24   \n",
       "5435           17                 8             3.727273        0.23   \n",
       "\n",
       "      ratio_of_4  ratio_of_long_words  total_unique_words  punctuation_count  \\\n",
       "0           0.22                 0.02                 531                 87   \n",
       "1           0.23                 0.01                 526                 77   \n",
       "2           0.25                 0.02                 571                100   \n",
       "3           0.24                 0.00                 266                 30   \n",
       "4           0.20                 0.01                 442                 49   \n",
       "...          ...                  ...                 ...                ...   \n",
       "5431        0.21                 0.01                 662                 64   \n",
       "5432        0.20                 0.02                 430                 52   \n",
       "5433        0.20                 0.02                 381                 69   \n",
       "5434        0.23                 0.02                 561                 87   \n",
       "5435        0.17                 0.05                 368                 46   \n",
       "\n",
       "      ...  average_paragraph_length  min_paragraph_length  \\\n",
       "0     ...                357.133333                   244   \n",
       "1     ...                746.000000                   316   \n",
       "2     ...               1000.000000                   475   \n",
       "3     ...                211.230769                   162   \n",
       "4     ...                454.272727                   270   \n",
       "...   ...                       ...                   ...   \n",
       "5431  ...                695.900000                   265   \n",
       "5432  ...               4563.000000                  4563   \n",
       "5433  ...                599.333333                   253   \n",
       "5434  ...                730.875000                   257   \n",
       "5435  ...                374.666667                   174   \n",
       "\n",
       "      max_paragraph_length  average_words_per_paragraph  \\\n",
       "0                      480                    76.466667   \n",
       "1                     1769                   166.571429   \n",
       "2                     1710                   210.166667   \n",
       "3                      305                    47.076923   \n",
       "4                      694                   103.909091   \n",
       "...                    ...                          ...   \n",
       "5431                  1153                   152.200000   \n",
       "5432                  4563                  1007.000000   \n",
       "5433                  1728                   133.166667   \n",
       "5434                  1817                   157.000000   \n",
       "5435                   766                    79.444444   \n",
       "\n",
       "      average_sentences_per_paragraph  punctuation_ratio_per_para  \\\n",
       "0                           78.266667                    0.075850   \n",
       "1                          167.285714                    0.066038   \n",
       "2                          213.833333                    0.079302   \n",
       "3                           47.153846                    0.049020   \n",
       "4                          104.090909                    0.042870   \n",
       "...                               ...                         ...   \n",
       "5431                       152.600000                    0.042050   \n",
       "5432                      1008.000000                    0.051639   \n",
       "5433                       134.333333                    0.086358   \n",
       "5434                       159.250000                    0.069268   \n",
       "5435                        79.222222                    0.064336   \n",
       "\n",
       "      average_question_marks_per_paragraph  lexical_density   entropy  \\\n",
       "0                                 0.133333         0.462947  4.437910   \n",
       "1                                 0.000000         0.451115  4.375210   \n",
       "2                                 0.166667         0.452815  4.452497   \n",
       "3                                 0.000000         0.434641  4.385417   \n",
       "4                                 0.000000         0.386702  4.331698   \n",
       "...                                    ...              ...       ...   \n",
       "5431                              0.000000         0.434954  4.389411   \n",
       "5432                              1.000000         0.427011  4.282201   \n",
       "5433                              0.000000         0.476846  4.422597   \n",
       "5434                              0.875000         0.446656  4.497136   \n",
       "5435                              0.000000         0.514685  4.451969   \n",
       "\n",
       "                Label  \n",
       "0     Non-Plagiarized  \n",
       "1         Plagiarized  \n",
       "2     Non-Plagiarized  \n",
       "3         Plagiarized  \n",
       "4     Non-Plagiarized  \n",
       "...               ...  \n",
       "5431      Plagiarized  \n",
       "5432  Non-Plagiarized  \n",
       "5433      Plagiarized  \n",
       "5434  Non-Plagiarized  \n",
       "5435      Plagiarized  \n",
       "\n",
       "[5436 rows x 45 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store Sen-level Dataset into .csv File and Dataframe\n",
    "\n",
    "# Convert Stylometry Features list into Dataframe    \n",
    "sen_stylometry_features = pd.DataFrame(stylometry_features_list_sentence_level)\n",
    "\n",
    "# adding header row accoring to the extracted stylometry feature\n",
    "sen_stylometry_features.columns = ['total_words', 'total_lines', 'empty_line_count', 'average_word_length', 'ratio_of_3', 'ratio_of_4', 'ratio_of_long_words', 'total_unique_words', 'punctuation_count', 'punctuation_ratio', 'comma_count', 'dashes_count', 'open_parentheses_count', 'close_parentheses_count', 'semicolons_count', 'white_spaces_count', 'question_marks_count', 'exclamation_marks_count', 'ampersands_count', 'percentage_signs', 'number_of_single_quotes', 'number_of_double_quotes', 'colons_count', 'number_of_characters_without_spaces', 'digit_count', 'no_of_all_brackets', 'total_sentences', 'average_sentence_length_in_words', 'average_sentence_length_in_char', 'min_sentence_length', 'max_sentence_length', 'average_spaces_per_sentence', 'total_question_sentences', 'total_paragraphs', 'average_paragraph_length', 'min_paragraph_length', 'max_paragraph_length', 'average_words_per_paragraph', 'average_sentences_per_paragraph', 'punctuation_ratio_per_para', 'average_question_marks_per_paragraph', 'lexical_density', 'entropy']\n",
    "\n",
    "# Combine the Input Feature Vectors and Output Label\n",
    "sen_stylometry_features = pd.concat([dataset_sen[['File Names']], sen_stylometry_features, dataset_sen[['Label']]], axis=1)\n",
    "\n",
    "# store results into .csv file\n",
    "sen_stylometry_features.to_csv(r'sen_stylometry_features.csv', index = False, header=True)\n",
    "\n",
    "# Display all Stylometric Features of Dataset\n",
    "print(\"\\nStylometry Features of Sen-Level Dataset :\")\n",
    "print(\"============================================\\n\")\n",
    "sen_stylometry_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fd6fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- Extract Stylometry Features of Sentence+Para-Level Dataset\n",
    "\n",
    "# list of all extracted features\n",
    "stylometry_features_list_complete = []\n",
    "\n",
    "for row in dataset_complete['Urdu Text']:\n",
    "           \n",
    "    ## resolving single \\n and double \\n problem\n",
    "    # Replace '\\n\\n' with a space to join paragraphs\n",
    "    text = row.replace('\\n\\n', '%%')\n",
    "\n",
    "    # Replace '\\n' with a space to join paragraphs\n",
    "    text = text.replace('\\n', '%%')\n",
    "\n",
    "    # Split the text into paragraphs based on the space character\n",
    "    paragraphs = text.split('%%')\n",
    "\n",
    "    # Remove any empty spaces\n",
    "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "\n",
    "    # paragraphs which are large but dont endswith(-), - sign inserted at the end of those paragraphs\n",
    "    # removing paragraphs which are small and dont endswith('-') and small bullet points\n",
    "\n",
    "    paragraph_list = []\n",
    "    for p in paragraphs:\n",
    "        if len(p)<80: # small paragraphs excluded \n",
    "            continue\n",
    "        elif (not p.endswith('۔') and not p.endswith('.') and not p.endswith('؟') and not p.endswith('؛')) and len(p)>150:\n",
    "            paragraph_list.append(p + '۔') # large paragraphs without ending on -, handeled here\n",
    "        elif (p.endswith('۔') or p.endswith('.') or p.endswith('؟') or p.endswith('؛')):\n",
    "            paragraph_list.append(p) #paragraphs added to list\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    text = '\\n\\n'.join(paragraph_list)  \n",
    "\n",
    "    # Write the results to list\n",
    "    stylometry_features_list_complete.append(calculate_text_features(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "698e5635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Stylometry Features of Complete Dataset :\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Names</th>\n",
       "      <th>total_words</th>\n",
       "      <th>total_lines</th>\n",
       "      <th>empty_line_count</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>ratio_of_3</th>\n",
       "      <th>ratio_of_4</th>\n",
       "      <th>ratio_of_long_words</th>\n",
       "      <th>total_unique_words</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>...</th>\n",
       "      <th>average_paragraph_length</th>\n",
       "      <th>min_paragraph_length</th>\n",
       "      <th>max_paragraph_length</th>\n",
       "      <th>average_words_per_paragraph</th>\n",
       "      <th>average_sentences_per_paragraph</th>\n",
       "      <th>punctuation_ratio_per_para</th>\n",
       "      <th>average_question_marks_per_paragraph</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>entropy</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1147</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>3.682650</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.02</td>\n",
       "      <td>531</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>357.133333</td>\n",
       "      <td>244</td>\n",
       "      <td>480</td>\n",
       "      <td>76.466667</td>\n",
       "      <td>78.266667</td>\n",
       "      <td>0.075850</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.462947</td>\n",
       "      <td>4.437910</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1166</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3.484563</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>526</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>316</td>\n",
       "      <td>1769</td>\n",
       "      <td>166.571429</td>\n",
       "      <td>167.285714</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451115</td>\n",
       "      <td>4.375210</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1261</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3.762887</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.02</td>\n",
       "      <td>571</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>475</td>\n",
       "      <td>1710</td>\n",
       "      <td>210.166667</td>\n",
       "      <td>213.833333</td>\n",
       "      <td>0.079302</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.452815</td>\n",
       "      <td>4.452497</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>612</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>3.508170</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>266</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>211.230769</td>\n",
       "      <td>162</td>\n",
       "      <td>305</td>\n",
       "      <td>47.076923</td>\n",
       "      <td>47.153846</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434641</td>\n",
       "      <td>4.385417</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1143</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>3.381452</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>442</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>454.272727</td>\n",
       "      <td>270</td>\n",
       "      <td>694</td>\n",
       "      <td>103.909091</td>\n",
       "      <td>104.090909</td>\n",
       "      <td>0.042870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386702</td>\n",
       "      <td>4.331698</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10867</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1529</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>3.578810</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.01</td>\n",
       "      <td>661</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>635.454545</td>\n",
       "      <td>162</td>\n",
       "      <td>1022</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>139.272727</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432309</td>\n",
       "      <td>4.383694</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10868</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1556</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>3.475578</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>691</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>534.692308</td>\n",
       "      <td>109</td>\n",
       "      <td>772</td>\n",
       "      <td>119.692308</td>\n",
       "      <td>120.615385</td>\n",
       "      <td>0.073907</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>0.444087</td>\n",
       "      <td>4.386175</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10869</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>814</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3.523342</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>388</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>224</td>\n",
       "      <td>1728</td>\n",
       "      <td>116.285714</td>\n",
       "      <td>117.714286</td>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476658</td>\n",
       "      <td>4.431409</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>1827</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>3.550082</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>631</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>638.769231</td>\n",
       "      <td>318</td>\n",
       "      <td>880</td>\n",
       "      <td>140.538462</td>\n",
       "      <td>140.307692</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345375</td>\n",
       "      <td>4.423068</td>\n",
       "      <td>Non-Plagiarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10871</th>\n",
       "      <td>C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...</td>\n",
       "      <td>616</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>3.759740</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>326</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>324.888889</td>\n",
       "      <td>174</td>\n",
       "      <td>635</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529221</td>\n",
       "      <td>4.459937</td>\n",
       "      <td>Plagiarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10872 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              File Names  total_words  \\\n",
       "0      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1147   \n",
       "1      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1166   \n",
       "2      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1261   \n",
       "3      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          612   \n",
       "4      C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1143   \n",
       "...                                                  ...          ...   \n",
       "10867  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1529   \n",
       "10868  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1556   \n",
       "10869  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          814   \n",
       "10870  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...         1827   \n",
       "10871  C:\\\\Users\\\\hasee\\\\Desktop\\\\baby projects\\\\0 Da...          616   \n",
       "\n",
       "       total_lines  empty_line_count  average_word_length  ratio_of_3  \\\n",
       "0               29                14             3.682650        0.24   \n",
       "1               13                 6             3.484563        0.26   \n",
       "2               11                 5             3.762887        0.23   \n",
       "3               25                12             3.508170        0.25   \n",
       "4               21                10             3.381452        0.27   \n",
       "...            ...               ...                  ...         ...   \n",
       "10867           21                10             3.578810        0.25   \n",
       "10868           25                12             3.475578        0.23   \n",
       "10869           13                 6             3.523342        0.23   \n",
       "10870           25                12             3.550082        0.26   \n",
       "10871           17                 8             3.759740        0.25   \n",
       "\n",
       "       ratio_of_4  ratio_of_long_words  total_unique_words  punctuation_count  \\\n",
       "0            0.22                 0.02                 531                 87   \n",
       "1            0.23                 0.01                 526                 77   \n",
       "2            0.25                 0.02                 571                100   \n",
       "3            0.24                 0.00                 266                 30   \n",
       "4            0.20                 0.01                 442                 49   \n",
       "...           ...                  ...                 ...                ...   \n",
       "10867        0.21                 0.01                 661                 64   \n",
       "10868        0.25                 0.01                 691                115   \n",
       "10869        0.21                 0.02                 388                 73   \n",
       "10870        0.24                 0.01                 631                 14   \n",
       "10871        0.17                 0.05                 326                 42   \n",
       "\n",
       "       ...  average_paragraph_length  min_paragraph_length  \\\n",
       "0      ...                357.133333                   244   \n",
       "1      ...                746.000000                   316   \n",
       "2      ...               1000.000000                   475   \n",
       "3      ...                211.230769                   162   \n",
       "4      ...                454.272727                   270   \n",
       "...    ...                       ...                   ...   \n",
       "10867  ...                635.454545                   162   \n",
       "10868  ...                534.692308                   109   \n",
       "10869  ...                525.000000                   224   \n",
       "10870  ...                638.769231                   318   \n",
       "10871  ...                324.888889                   174   \n",
       "\n",
       "       max_paragraph_length  average_words_per_paragraph  \\\n",
       "0                       480                    76.466667   \n",
       "1                      1769                   166.571429   \n",
       "2                      1710                   210.166667   \n",
       "3                       305                    47.076923   \n",
       "4                       694                   103.909091   \n",
       "...                     ...                          ...   \n",
       "10867                  1022                   139.000000   \n",
       "10868                   772                   119.692308   \n",
       "10869                  1728                   116.285714   \n",
       "10870                   880                   140.538462   \n",
       "10871                   635                    68.444444   \n",
       "\n",
       "       average_sentences_per_paragraph  punctuation_ratio_per_para  \\\n",
       "0                            78.266667                    0.075850   \n",
       "1                           167.285714                    0.066038   \n",
       "2                           213.833333                    0.079302   \n",
       "3                            47.153846                    0.049020   \n",
       "4                           104.090909                    0.042870   \n",
       "...                                ...                         ...   \n",
       "10867                       139.272727                    0.041857   \n",
       "10868                       120.615385                    0.073907   \n",
       "10869                       117.714286                    0.089681   \n",
       "10870                       140.307692                    0.007663   \n",
       "10871                        68.444444                    0.068182   \n",
       "\n",
       "       average_question_marks_per_paragraph  lexical_density   entropy  \\\n",
       "0                                  0.133333         0.462947  4.437910   \n",
       "1                                  0.000000         0.451115  4.375210   \n",
       "2                                  0.166667         0.452815  4.452497   \n",
       "3                                  0.000000         0.434641  4.385417   \n",
       "4                                  0.000000         0.386702  4.331698   \n",
       "...                                     ...              ...       ...   \n",
       "10867                              0.000000         0.432309  4.383694   \n",
       "10868                              1.384615         0.444087  4.386175   \n",
       "10869                              0.000000         0.476658  4.431409   \n",
       "10870                              0.000000         0.345375  4.423068   \n",
       "10871                              0.000000         0.529221  4.459937   \n",
       "\n",
       "                 Label  \n",
       "0      Non-Plagiarized  \n",
       "1          Plagiarized  \n",
       "2      Non-Plagiarized  \n",
       "3          Plagiarized  \n",
       "4      Non-Plagiarized  \n",
       "...                ...  \n",
       "10867      Plagiarized  \n",
       "10868  Non-Plagiarized  \n",
       "10869      Plagiarized  \n",
       "10870  Non-Plagiarized  \n",
       "10871      Plagiarized  \n",
       "\n",
       "[10872 rows x 45 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store Sen+Para-Level dataset into .csv File and Dataframe\n",
    "\n",
    "# Convert Stylometry Features list into Dataframe    \n",
    "all_stylometry_features = pd.DataFrame(stylometry_features_list_complete)\n",
    "\n",
    "# adding header row accoring to the extracted stylometry feature\n",
    "all_stylometry_features.columns = ['total_words', 'total_lines', 'empty_line_count', 'average_word_length', 'ratio_of_3', 'ratio_of_4', 'ratio_of_long_words', 'total_unique_words', 'punctuation_count', 'punctuation_ratio', 'comma_count', 'dashes_count', 'open_parentheses_count', 'close_parentheses_count', 'semicolons_count', 'white_spaces_count', 'question_marks_count', 'exclamation_marks_count', 'ampersands_count', 'percentage_signs', 'number_of_single_quotes', 'number_of_double_quotes', 'colons_count', 'number_of_characters_without_spaces', 'digit_count', 'no_of_all_brackets', 'total_sentences', 'average_sentence_length_in_words', 'average_sentence_length_in_char', 'min_sentence_length', 'max_sentence_length', 'average_spaces_per_sentence', 'total_question_sentences', 'total_paragraphs', 'average_paragraph_length', 'min_paragraph_length', 'max_paragraph_length', 'average_words_per_paragraph', 'average_sentences_per_paragraph', 'punctuation_ratio_per_para', 'average_question_marks_per_paragraph', 'lexical_density', 'entropy']\n",
    "\n",
    "# Combine the Input Feature Vectors and Output Label\n",
    "all_stylometry_features = pd.concat([dataset_complete[['File Names']], all_stylometry_features, dataset_complete[['Label']]], axis=1)\n",
    "\n",
    "# store results into .csv file\n",
    "all_stylometry_features.to_csv(r'all_stylometry_features.csv', index = False, header=True)\n",
    "\n",
    "# Display all Stylometric Features of Dataset\n",
    "print(\"\\nAll Stylometry Features of Complete Dataset :\")\n",
    "print(\"================================================\\n\")\n",
    "all_stylometry_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a20c1fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column of file names\n",
    "sen_level_Dataset_features = sen_stylometry_features.drop(['File Names'], axis=1)\n",
    "para_level_Dataset_features = para_stylometry_features.drop(['File Names'], axis=1)\n",
    "all_level_Dataset_features = all_stylometry_features.drop(['File Names'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef92fb",
   "metadata": {},
   "source": [
    "### 4. Apply Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5496f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Sen-Level Label column values into digits\n",
    "label_encoder = LabelEncoder()\n",
    "sen_level_Dataset_features['Label'] = label_encoder.fit_transform(sen_level_Dataset_features['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88c5d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Para-Level Label column values into digits\n",
    "para_level_Dataset_features['Label'] = label_encoder.fit_transform(para_level_Dataset_features['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c43ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Sen+Para-Level Label column values into digits\n",
    "all_level_Dataset_features['Label'] = label_encoder.fit_transform(all_level_Dataset_features['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a51c6c",
   "metadata": {},
   "source": [
    "### Lets apply 10 ML Agorithms given below\n",
    "i.Decison Tree\n",
    "ii. Logistic Regression\n",
    "iii. Random Forest\n",
    "iv. Support Vector Machines (SVM)\n",
    "v. K-Nearest Neighbors (KNN)\n",
    "vi. Naive Bayes\n",
    "vii. Gradient Boosting Machines\n",
    "viii. Linear Discriminant Analysis (LDA)\n",
    "ix. Ensemble Learning (Voting Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a6823",
   "metadata": {},
   "source": [
    "##### 4.1 Apply Machine Learning Algorithms on 1. Sen-Level Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251bd50e",
   "metadata": {},
   "source": [
    "###### 4.1.1. All stylometry features (43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4896019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = sen_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "y = sen_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bcffb86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and All stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.8318\n",
      "precision: 0.8444\n",
      "recall: 0.8150\n",
      "f1: 0.8295\n",
      "Confusion Matrix:\n",
      "[[460  82]\n",
      " [101 445]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9825\n",
      "precision: 0.9714\n",
      "recall: 0.9945\n",
      "f1: 0.9828\n",
      "Confusion Matrix:\n",
      "[[526  16]\n",
      " [  3 543]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9991\n",
      "precision: 0.9982\n",
      "recall: 1.0000\n",
      "f1: 0.9991\n",
      "Confusion Matrix:\n",
      "[[541   1]\n",
      " [  0 546]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.8382\n",
      "precision: 0.9322\n",
      "recall: 0.7308\n",
      "f1: 0.8193\n",
      "Confusion Matrix:\n",
      "[[513  29]\n",
      " [147 399]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.9439\n",
      "precision: 0.9131\n",
      "recall: 0.9817\n",
      "f1: 0.9462\n",
      "Confusion Matrix:\n",
      "[[491  51]\n",
      " [ 10 536]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.7518\n",
      "precision: 0.9367\n",
      "recall: 0.5421\n",
      "f1: 0.6868\n",
      "Confusion Matrix:\n",
      "[[522  20]\n",
      " [250 296]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.8686\n",
      "precision: 0.8913\n",
      "recall: 0.8407\n",
      "f1: 0.8652\n",
      "Confusion Matrix:\n",
      "[[486  56]\n",
      " [ 87 459]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.8925\n",
      "precision: 0.9214\n",
      "recall: 0.8590\n",
      "f1: 0.8891\n",
      "Confusion Matrix:\n",
      "[[502  40]\n",
      " [ 77 469]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9890\n",
      "precision: 0.9802\n",
      "recall: 0.9982\n",
      "f1: 0.9891\n",
      "Confusion Matrix:\n",
      "[[531  11]\n",
      " [  1 545]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.9779\n",
      "precision: 0.9763\n",
      "recall: 0.9799\n",
      "f1: 0.9781\n",
      "Confusion Matrix:\n",
      "[[529  13]\n",
      " [ 11 535]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and All stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b8da7",
   "metadata": {},
   "source": [
    "###### 4.1.2. Word-Level stylometry features (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1586414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = sen_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 0:10] #Word-Level stylometry features \n",
    "y = sen_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb8ad175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and Word-Level Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.7040\n",
      "precision: 0.7146\n",
      "recall: 0.6832\n",
      "f1: 0.6985\n",
      "Confusion Matrix:\n",
      "[[393 149]\n",
      " [173 373]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9715\n",
      "precision: 0.9574\n",
      "recall: 0.9872\n",
      "f1: 0.9720\n",
      "Confusion Matrix:\n",
      "[[518  24]\n",
      " [  7 539]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9936\n",
      "precision: 0.9909\n",
      "recall: 0.9963\n",
      "f1: 0.9936\n",
      "Confusion Matrix:\n",
      "[[537   5]\n",
      " [  2 544]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7895\n",
      "precision: 0.9594\n",
      "recall: 0.6062\n",
      "f1: 0.7430\n",
      "Confusion Matrix:\n",
      "[[528  14]\n",
      " [215 331]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.9301\n",
      "precision: 0.8997\n",
      "recall: 0.9689\n",
      "f1: 0.9330\n",
      "Confusion Matrix:\n",
      "[[483  59]\n",
      " [ 17 529]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.7601\n",
      "precision: 0.9331\n",
      "recall: 0.5623\n",
      "f1: 0.7017\n",
      "Confusion Matrix:\n",
      "[[520  22]\n",
      " [239 307]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7252\n",
      "precision: 0.7589\n",
      "recall: 0.6630\n",
      "f1: 0.7077\n",
      "Confusion Matrix:\n",
      "[[427 115]\n",
      " [184 362]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.7721\n",
      "precision: 0.8706\n",
      "recall: 0.6410\n",
      "f1: 0.7384\n",
      "Confusion Matrix:\n",
      "[[490  52]\n",
      " [196 350]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9347\n",
      "precision: 0.9507\n",
      "recall: 0.9176\n",
      "f1: 0.9338\n",
      "Confusion Matrix:\n",
      "[[516  26]\n",
      " [ 45 501]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.9439\n",
      "precision: 0.9764\n",
      "recall: 0.9103\n",
      "f1: 0.9422\n",
      "Confusion Matrix:\n",
      "[[530  12]\n",
      " [ 49 497]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and Word-Level Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d1278",
   "metadata": {},
   "source": [
    "###### 4.1.3. Character-Level stylometry features (16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5a77b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = sen_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 10:26] #Character-Level stylometry features \n",
    "y = sen_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0fcdae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and Character-Level Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.7776\n",
      "precision: 0.7957\n",
      "recall: 0.7491\n",
      "f1: 0.7717\n",
      "Confusion Matrix:\n",
      "[[437 105]\n",
      " [137 409]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9706\n",
      "precision: 0.9622\n",
      "recall: 0.9799\n",
      "f1: 0.9710\n",
      "Confusion Matrix:\n",
      "[[521  21]\n",
      " [ 11 535]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9862\n",
      "precision: 0.9854\n",
      "recall: 0.9872\n",
      "f1: 0.9863\n",
      "Confusion Matrix:\n",
      "[[534   8]\n",
      " [  7 539]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7904\n",
      "precision: 0.9649\n",
      "recall: 0.6044\n",
      "f1: 0.7432\n",
      "Confusion Matrix:\n",
      "[[530  12]\n",
      " [216 330]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.9072\n",
      "precision: 0.8803\n",
      "recall: 0.9432\n",
      "f1: 0.9107\n",
      "Confusion Matrix:\n",
      "[[472  70]\n",
      " [ 31 515]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.7233\n",
      "precision: 0.9554\n",
      "recall: 0.4707\n",
      "f1: 0.6307\n",
      "Confusion Matrix:\n",
      "[[530  12]\n",
      " [289 257]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7675\n",
      "precision: 0.7708\n",
      "recall: 0.7637\n",
      "f1: 0.7672\n",
      "Confusion Matrix:\n",
      "[[418 124]\n",
      " [129 417]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.5055\n",
      "precision: 0.5037\n",
      "recall: 1.0000\n",
      "f1: 0.6699\n",
      "Confusion Matrix:\n",
      "[[  4 538]\n",
      " [  0 546]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9458\n",
      "precision: 0.9501\n",
      "recall: 0.9414\n",
      "f1: 0.9457\n",
      "Confusion Matrix:\n",
      "[[515  27]\n",
      " [ 32 514]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.9449\n",
      "precision: 0.9765\n",
      "recall: 0.9121\n",
      "f1: 0.9432\n",
      "Confusion Matrix:\n",
      "[[530  12]\n",
      " [ 48 498]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and Character-Level Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0a435",
   "metadata": {},
   "source": [
    "###### 4.1.4. Sentence-Level stylometry features (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c426508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = sen_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 26:33] #Sentence-Level stylometry features \n",
    "y = sen_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4499f0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and Sentence-Level Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.5708\n",
      "precision: 0.5776\n",
      "recall: 0.5385\n",
      "f1: 0.5573\n",
      "Confusion Matrix:\n",
      "[[327 215]\n",
      " [252 294]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9596\n",
      "precision: 0.9580\n",
      "recall: 0.9615\n",
      "f1: 0.9598\n",
      "Confusion Matrix:\n",
      "[[519  23]\n",
      " [ 21 525]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9715\n",
      "precision: 0.9656\n",
      "recall: 0.9780\n",
      "f1: 0.9718\n",
      "Confusion Matrix:\n",
      "[[523  19]\n",
      " [ 12 534]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7243\n",
      "precision: 0.8555\n",
      "recall: 0.5421\n",
      "f1: 0.6637\n",
      "Confusion Matrix:\n",
      "[[492  50]\n",
      " [250 296]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.9228\n",
      "precision: 0.8915\n",
      "recall: 0.9634\n",
      "f1: 0.9261\n",
      "Confusion Matrix:\n",
      "[[478  64]\n",
      " [ 20 526]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.5836\n",
      "precision: 0.7541\n",
      "recall: 0.2527\n",
      "f1: 0.3786\n",
      "Confusion Matrix:\n",
      "[[497  45]\n",
      " [408 138]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.5735\n",
      "precision: 0.5817\n",
      "recall: 0.5348\n",
      "f1: 0.5573\n",
      "Confusion Matrix:\n",
      "[[332 210]\n",
      " [254 292]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.7904\n",
      "precision: 0.7548\n",
      "recall: 0.8626\n",
      "f1: 0.8051\n",
      "Confusion Matrix:\n",
      "[[389 153]\n",
      " [ 75 471]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.8971\n",
      "precision: 0.9205\n",
      "recall: 0.8700\n",
      "f1: 0.8945\n",
      "Confusion Matrix:\n",
      "[[501  41]\n",
      " [ 71 475]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.9044\n",
      "precision: 0.9402\n",
      "recall: 0.8645\n",
      "f1: 0.9008\n",
      "Confusion Matrix:\n",
      "[[512  30]\n",
      " [ 74 472]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and Sentence-Level Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c562264b",
   "metadata": {},
   "source": [
    "###### 4.1.5. Para-Level stylometry features, Document-Level stylometry features, Textual Entropy stylometry features (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55d72045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = sen_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 33:]\n",
    "y = sen_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6979f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and Para-Level , Document-Level, Textual Entropy Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.6792\n",
      "precision: 0.7627\n",
      "recall: 0.5238\n",
      "f1: 0.6211\n",
      "Confusion Matrix:\n",
      "[[453  89]\n",
      " [260 286]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9568\n",
      "precision: 0.9416\n",
      "recall: 0.9744\n",
      "f1: 0.9577\n",
      "Confusion Matrix:\n",
      "[[509  33]\n",
      " [ 14 532]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9853\n",
      "precision: 0.9836\n",
      "recall: 0.9872\n",
      "f1: 0.9854\n",
      "Confusion Matrix:\n",
      "[[533   9]\n",
      " [  7 539]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7619\n",
      "precision: 0.8345\n",
      "recall: 0.6557\n",
      "f1: 0.7344\n",
      "Confusion Matrix:\n",
      "[[471  71]\n",
      " [188 358]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8796\n",
      "precision: 0.8571\n",
      "recall: 0.9121\n",
      "f1: 0.8838\n",
      "Confusion Matrix:\n",
      "[[459  83]\n",
      " [ 48 498]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.6461\n",
      "precision: 0.8286\n",
      "recall: 0.3718\n",
      "f1: 0.5133\n",
      "Confusion Matrix:\n",
      "[[500  42]\n",
      " [343 203]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7316\n",
      "precision: 0.7810\n",
      "recall: 0.6465\n",
      "f1: 0.7074\n",
      "Confusion Matrix:\n",
      "[[443  99]\n",
      " [193 353]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.7325\n",
      "precision: 0.8382\n",
      "recall: 0.5788\n",
      "f1: 0.6847\n",
      "Confusion Matrix:\n",
      "[[481  61]\n",
      " [230 316]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9347\n",
      "precision: 0.9310\n",
      "recall: 0.9396\n",
      "f1: 0.9353\n",
      "Confusion Matrix:\n",
      "[[504  38]\n",
      " [ 33 513]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.8824\n",
      "precision: 0.9428\n",
      "recall: 0.8150\n",
      "f1: 0.8743\n",
      "Confusion Matrix:\n",
      "[[515  27]\n",
      " [101 445]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 1. Sen-Level Dataset and Para-Level , Document-Level, Textual Entropy Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98966f58",
   "metadata": {},
   "source": [
    "##### 4.2 Apply Machine Learning Algorithms on 2. Para-Level Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ce146",
   "metadata": {},
   "source": [
    "###### 4.2.1. All stylometry features (43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01b1b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = para_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "y = para_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2cc1710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and All stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.8382\n",
      "precision: 0.8599\n",
      "recall: 0.8095\n",
      "f1: 0.8340\n",
      "Confusion Matrix:\n",
      "[[470  72]\n",
      " [104 442]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9669\n",
      "precision: 0.9620\n",
      "recall: 0.9725\n",
      "f1: 0.9672\n",
      "Confusion Matrix:\n",
      "[[521  21]\n",
      " [ 15 531]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9881\n",
      "precision: 0.9890\n",
      "recall: 0.9872\n",
      "f1: 0.9881\n",
      "Confusion Matrix:\n",
      "[[536   6]\n",
      " [  7 539]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.8419\n",
      "precision: 0.8864\n",
      "recall: 0.7857\n",
      "f1: 0.8330\n",
      "Confusion Matrix:\n",
      "[[487  55]\n",
      " [117 429]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.9154\n",
      "precision: 0.8861\n",
      "recall: 0.9542\n",
      "f1: 0.9189\n",
      "Confusion Matrix:\n",
      "[[475  67]\n",
      " [ 25 521]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.7638\n",
      "precision: 0.9392\n",
      "recall: 0.5659\n",
      "f1: 0.7063\n",
      "Confusion Matrix:\n",
      "[[522  20]\n",
      " [237 309]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.8778\n",
      "precision: 0.8681\n",
      "recall: 0.8919\n",
      "f1: 0.8799\n",
      "Confusion Matrix:\n",
      "[[468  74]\n",
      " [ 59 487]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.8667\n",
      "precision: 0.9134\n",
      "recall: 0.8114\n",
      "f1: 0.8594\n",
      "Confusion Matrix:\n",
      "[[500  42]\n",
      " [103 443]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9779\n",
      "precision: 0.9745\n",
      "recall: 0.9817\n",
      "f1: 0.9781\n",
      "Confusion Matrix:\n",
      "[[528  14]\n",
      " [ 10 536]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.9596\n",
      "precision: 0.9718\n",
      "recall: 0.9469\n",
      "f1: 0.9592\n",
      "Confusion Matrix:\n",
      "[[527  15]\n",
      " [ 29 517]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and All stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c9240c",
   "metadata": {},
   "source": [
    "###### 4.2.2. Word-Level stylometry features (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cecc5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = para_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 0:10] #Word-Level stylometry features \n",
    "y = para_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9bfa2b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and Word-Level Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.7096\n",
      "precision: 0.7054\n",
      "recall: 0.7234\n",
      "f1: 0.7143\n",
      "Confusion Matrix:\n",
      "[[377 165]\n",
      " [151 395]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9035\n",
      "precision: 0.9002\n",
      "recall: 0.9084\n",
      "f1: 0.9043\n",
      "Confusion Matrix:\n",
      "[[487  55]\n",
      " [ 50 496]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9550\n",
      "precision: 0.9680\n",
      "recall: 0.9414\n",
      "f1: 0.9545\n",
      "Confusion Matrix:\n",
      "[[525  17]\n",
      " [ 32 514]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7454\n",
      "precision: 0.8768\n",
      "recall: 0.5733\n",
      "f1: 0.6932\n",
      "Confusion Matrix:\n",
      "[[498  44]\n",
      " [233 313]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8208\n",
      "precision: 0.8117\n",
      "recall: 0.8370\n",
      "f1: 0.8242\n",
      "Confusion Matrix:\n",
      "[[436 106]\n",
      " [ 89 457]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.6581\n",
      "precision: 0.9065\n",
      "recall: 0.3553\n",
      "f1: 0.5105\n",
      "Confusion Matrix:\n",
      "[[522  20]\n",
      " [352 194]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7215\n",
      "precision: 0.7425\n",
      "recall: 0.6813\n",
      "f1: 0.7106\n",
      "Confusion Matrix:\n",
      "[[413 129]\n",
      " [174 372]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.6517\n",
      "precision: 0.6000\n",
      "recall: 0.9176\n",
      "f1: 0.7256\n",
      "Confusion Matrix:\n",
      "[[208 334]\n",
      " [ 45 501]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.8943\n",
      "precision: 0.9250\n",
      "recall: 0.8590\n",
      "f1: 0.8908\n",
      "Confusion Matrix:\n",
      "[[504  38]\n",
      " [ 77 469]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.8824\n",
      "precision: 0.9391\n",
      "recall: 0.8187\n",
      "f1: 0.8748\n",
      "Confusion Matrix:\n",
      "[[513  29]\n",
      " [ 99 447]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and Word-Level Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c99371",
   "metadata": {},
   "source": [
    "###### 4.2.3. Character-Level stylometry features (16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bcba140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = para_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 10:26] #Character-Level stylometry features \n",
    "y = para_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6aa456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and Character-Level Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.7592\n",
      "precision: 0.7630\n",
      "recall: 0.7546\n",
      "f1: 0.7587\n",
      "Confusion Matrix:\n",
      "[[414 128]\n",
      " [134 412]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9421\n",
      "precision: 0.9399\n",
      "recall: 0.9451\n",
      "f1: 0.9425\n",
      "Confusion Matrix:\n",
      "[[509  33]\n",
      " [ 30 516]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9651\n",
      "precision: 0.9686\n",
      "recall: 0.9615\n",
      "f1: 0.9651\n",
      "Confusion Matrix:\n",
      "[[525  17]\n",
      " [ 21 525]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7454\n",
      "precision: 0.8645\n",
      "recall: 0.5842\n",
      "f1: 0.6973\n",
      "Confusion Matrix:\n",
      "[[492  50]\n",
      " [227 319]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8199\n",
      "precision: 0.8038\n",
      "recall: 0.8480\n",
      "f1: 0.8253\n",
      "Confusion Matrix:\n",
      "[[429 113]\n",
      " [ 83 463]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.6737\n",
      "precision: 0.9401\n",
      "recall: 0.3736\n",
      "f1: 0.5347\n",
      "Confusion Matrix:\n",
      "[[529  13]\n",
      " [342 204]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7417\n",
      "precision: 0.7219\n",
      "recall: 0.7894\n",
      "f1: 0.7542\n",
      "Confusion Matrix:\n",
      "[[376 166]\n",
      " [115 431]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.6048\n",
      "precision: 0.9833\n",
      "recall: 0.2161\n",
      "f1: 0.3544\n",
      "Confusion Matrix:\n",
      "[[540   2]\n",
      " [428 118]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9274\n",
      "precision: 0.9414\n",
      "recall: 0.9121\n",
      "f1: 0.9265\n",
      "Confusion Matrix:\n",
      "[[511  31]\n",
      " [ 48 498]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.9311\n",
      "precision: 0.9418\n",
      "recall: 0.9194\n",
      "f1: 0.9305\n",
      "Confusion Matrix:\n",
      "[[511  31]\n",
      " [ 44 502]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and Character-Level Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f08e8c",
   "metadata": {},
   "source": [
    "###### 4.2.4. Sentence-Level stylometry features (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b845d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = para_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 26:33] #Sentence-Level stylometry features \n",
    "y = para_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fc53bc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and Sentence-Level Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.6314\n",
      "precision: 0.6171\n",
      "recall: 0.6996\n",
      "f1: 0.6558\n",
      "Confusion Matrix:\n",
      "[[305 237]\n",
      " [164 382]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.8879\n",
      "precision: 0.8813\n",
      "recall: 0.8974\n",
      "f1: 0.8893\n",
      "Confusion Matrix:\n",
      "[[476  66]\n",
      " [ 56 490]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9228\n",
      "precision: 0.9278\n",
      "recall: 0.9176\n",
      "f1: 0.9227\n",
      "Confusion Matrix:\n",
      "[[503  39]\n",
      " [ 45 501]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7188\n",
      "precision: 0.7703\n",
      "recall: 0.6264\n",
      "f1: 0.6909\n",
      "Confusion Matrix:\n",
      "[[440 102]\n",
      " [204 342]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8520\n",
      "precision: 0.8302\n",
      "recall: 0.8864\n",
      "f1: 0.8574\n",
      "Confusion Matrix:\n",
      "[[443  99]\n",
      " [ 62 484]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.6048\n",
      "precision: 0.5695\n",
      "recall: 0.8700\n",
      "f1: 0.6884\n",
      "Confusion Matrix:\n",
      "[[183 359]\n",
      " [ 71 475]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.6287\n",
      "precision: 0.6102\n",
      "recall: 0.7198\n",
      "f1: 0.6605\n",
      "Confusion Matrix:\n",
      "[[291 251]\n",
      " [153 393]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.7583\n",
      "precision: 0.8393\n",
      "recall: 0.6410\n",
      "f1: 0.7269\n",
      "Confusion Matrix:\n",
      "[[475  67]\n",
      " [196 350]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.8585\n",
      "precision: 0.8643\n",
      "recall: 0.8516\n",
      "f1: 0.8579\n",
      "Confusion Matrix:\n",
      "[[469  73]\n",
      " [ 81 465]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.8529\n",
      "precision: 0.8154\n",
      "recall: 0.9139\n",
      "f1: 0.8618\n",
      "Confusion Matrix:\n",
      "[[429 113]\n",
      " [ 47 499]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and Sentence-Level Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26affca",
   "metadata": {},
   "source": [
    "###### 4.2.5. Para-Level stylometry features, Document-Level stylometry features, Textual Entropy stylometry features (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25954d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = para_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 33:]\n",
    "y = para_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "49a2c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and Para-Level , Document-Level, Textual Entropy Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.7629\n",
      "precision: 0.7857\n",
      "recall: 0.7253\n",
      "f1: 0.7543\n",
      "Confusion Matrix:\n",
      "[[434 108]\n",
      " [150 396]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9338\n",
      "precision: 0.9232\n",
      "recall: 0.9469\n",
      "f1: 0.9349\n",
      "Confusion Matrix:\n",
      "[[499  43]\n",
      " [ 29 517]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9688\n",
      "precision: 0.9588\n",
      "recall: 0.9799\n",
      "f1: 0.9692\n",
      "Confusion Matrix:\n",
      "[[519  23]\n",
      " [ 11 535]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7647\n",
      "precision: 0.8326\n",
      "recall: 0.6648\n",
      "f1: 0.7393\n",
      "Confusion Matrix:\n",
      "[[469  73]\n",
      " [183 363]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8548\n",
      "precision: 0.8380\n",
      "recall: 0.8810\n",
      "f1: 0.8589\n",
      "Confusion Matrix:\n",
      "[[449  93]\n",
      " [ 65 481]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.5754\n",
      "precision: 0.5435\n",
      "recall: 0.9615\n",
      "f1: 0.6944\n",
      "Confusion Matrix:\n",
      "[[101 441]\n",
      " [ 21 525]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7390\n",
      "precision: 0.7823\n",
      "recall: 0.6648\n",
      "f1: 0.7188\n",
      "Confusion Matrix:\n",
      "[[441 101]\n",
      " [183 363]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.7702\n",
      "precision: 0.7151\n",
      "recall: 0.9011\n",
      "f1: 0.7974\n",
      "Confusion Matrix:\n",
      "[[346 196]\n",
      " [ 54 492]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9311\n",
      "precision: 0.9290\n",
      "recall: 0.9341\n",
      "f1: 0.9315\n",
      "Confusion Matrix:\n",
      "[[503  39]\n",
      " [ 36 510]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.8915\n",
      "precision: 0.8768\n",
      "recall: 0.9121\n",
      "f1: 0.8941\n",
      "Confusion Matrix:\n",
      "[[472  70]\n",
      " [ 48 498]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 2. Para-Level Dataset and Para-Level , Document-Level, Textual Entropy Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf4add",
   "metadata": {},
   "source": [
    "##### 4.3 Apply Machine Learning Algorithms on 3. Sen+Para-Level Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfa0ad",
   "metadata": {},
   "source": [
    "###### 4.3.1. All stylometry features (43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3d183df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = all_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "y = all_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0332dd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and All stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.8152\n",
      "precision: 0.8238\n",
      "recall: 0.7879\n",
      "f1: 0.8054\n",
      "Confusion Matrix:\n",
      "[[941 178]\n",
      " [224 832]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9720\n",
      "precision: 0.9654\n",
      "recall: 0.9773\n",
      "f1: 0.9713\n",
      "Confusion Matrix:\n",
      "[[1082   37]\n",
      " [  24 1032]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9917\n",
      "precision: 0.9896\n",
      "recall: 0.9934\n",
      "f1: 0.9915\n",
      "Confusion Matrix:\n",
      "[[1108   11]\n",
      " [   7 1049]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.8552\n",
      "precision: 0.9186\n",
      "recall: 0.7699\n",
      "f1: 0.8377\n",
      "Confusion Matrix:\n",
      "[[1047   72]\n",
      " [ 243  813]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.9352\n",
      "precision: 0.9045\n",
      "recall: 0.9688\n",
      "f1: 0.9355\n",
      "Confusion Matrix:\n",
      "[[1011  108]\n",
      " [  33 1023]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.7421\n",
      "precision: 0.9381\n",
      "recall: 0.5019\n",
      "f1: 0.6539\n",
      "Confusion Matrix:\n",
      "[[1084   35]\n",
      " [ 526  530]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.8607\n",
      "precision: 0.8739\n",
      "recall: 0.8333\n",
      "f1: 0.8531\n",
      "Confusion Matrix:\n",
      "[[992 127]\n",
      " [176 880]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.8841\n",
      "precision: 0.9517\n",
      "recall: 0.8021\n",
      "f1: 0.8705\n",
      "Confusion Matrix:\n",
      "[[1076   43]\n",
      " [ 209  847]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9733\n",
      "precision: 0.9629\n",
      "recall: 0.9830\n",
      "f1: 0.9728\n",
      "Confusion Matrix:\n",
      "[[1079   40]\n",
      " [  18 1038]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.9582\n",
      "precision: 0.9791\n",
      "recall: 0.9337\n",
      "f1: 0.9559\n",
      "Confusion Matrix:\n",
      "[[1098   21]\n",
      " [  70  986]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and All stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88755c",
   "metadata": {},
   "source": [
    "###### 4.3.2. Word-Level stylometry features (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "321dfcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = all_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 0:10] #Word-Level stylometry features \n",
    "y = all_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17c2a29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and Word-Level stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.6901\n",
      "precision: 0.6816\n",
      "recall: 0.6790\n",
      "f1: 0.6803\n",
      "Confusion Matrix:\n",
      "[[784 335]\n",
      " [339 717]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9278\n",
      "precision: 0.9158\n",
      "recall: 0.9375\n",
      "f1: 0.9265\n",
      "Confusion Matrix:\n",
      "[[1028   91]\n",
      " [  66  990]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9669\n",
      "precision: 0.9740\n",
      "recall: 0.9574\n",
      "f1: 0.9656\n",
      "Confusion Matrix:\n",
      "[[1092   27]\n",
      " [  45 1011]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7752\n",
      "precision: 0.8987\n",
      "recall: 0.6051\n",
      "f1: 0.7233\n",
      "Confusion Matrix:\n",
      "[[1047   72]\n",
      " [ 417  639]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8878\n",
      "precision: 0.8658\n",
      "recall: 0.9100\n",
      "f1: 0.8873\n",
      "Confusion Matrix:\n",
      "[[970 149]\n",
      " [ 95 961]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.7085\n",
      "precision: 0.9089\n",
      "recall: 0.4441\n",
      "f1: 0.5967\n",
      "Confusion Matrix:\n",
      "[[1072   47]\n",
      " [ 587  469]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7021\n",
      "precision: 0.7121\n",
      "recall: 0.6487\n",
      "f1: 0.6789\n",
      "Confusion Matrix:\n",
      "[[842 277]\n",
      " [371 685]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.6910\n",
      "precision: 0.6600\n",
      "recall: 0.7500\n",
      "f1: 0.7021\n",
      "Confusion Matrix:\n",
      "[[711 408]\n",
      " [264 792]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.8915\n",
      "precision: 0.9209\n",
      "recall: 0.8494\n",
      "f1: 0.8837\n",
      "Confusion Matrix:\n",
      "[[1042   77]\n",
      " [ 159  897]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.8943\n",
      "precision: 0.9320\n",
      "recall: 0.8438\n",
      "f1: 0.8857\n",
      "Confusion Matrix:\n",
      "[[1054   65]\n",
      " [ 165  891]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and Word-Level stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fd037a",
   "metadata": {},
   "source": [
    "###### 4.3.3. Character-Level stylometry features (16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9b0947c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = all_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 10:26] #Character-Level stylometry features \n",
    "y = all_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f82e7bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and Character stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.7526\n",
      "precision: 0.7462\n",
      "recall: 0.7434\n",
      "f1: 0.7448\n",
      "Confusion Matrix:\n",
      "[[852 267]\n",
      " [271 785]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9582\n",
      "precision: 0.9514\n",
      "recall: 0.9631\n",
      "f1: 0.9572\n",
      "Confusion Matrix:\n",
      "[[1067   52]\n",
      " [  39 1017]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9811\n",
      "precision: 0.9801\n",
      "recall: 0.9811\n",
      "f1: 0.9806\n",
      "Confusion Matrix:\n",
      "[[1098   21]\n",
      " [  20 1036]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7706\n",
      "precision: 0.9126\n",
      "recall: 0.5833\n",
      "f1: 0.7117\n",
      "Confusion Matrix:\n",
      "[[1060   59]\n",
      " [ 440  616]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8713\n",
      "precision: 0.8514\n",
      "recall: 0.8902\n",
      "f1: 0.8704\n",
      "Confusion Matrix:\n",
      "[[955 164]\n",
      " [116 940]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.6938\n",
      "precision: 0.9185\n",
      "recall: 0.4053\n",
      "f1: 0.5624\n",
      "Confusion Matrix:\n",
      "[[1081   38]\n",
      " [ 628  428]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7320\n",
      "precision: 0.7066\n",
      "recall: 0.7661\n",
      "f1: 0.7351\n",
      "Confusion Matrix:\n",
      "[[783 336]\n",
      " [247 809]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.7320\n",
      "precision: 0.6870\n",
      "recall: 0.8229\n",
      "f1: 0.7488\n",
      "Confusion Matrix:\n",
      "[[723 396]\n",
      " [187 869]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9237\n",
      "precision: 0.9262\n",
      "recall: 0.9157\n",
      "f1: 0.9210\n",
      "Confusion Matrix:\n",
      "[[1042   77]\n",
      " [  89  967]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.9159\n",
      "precision: 0.9422\n",
      "recall: 0.8807\n",
      "f1: 0.9104\n",
      "Confusion Matrix:\n",
      "[[1062   57]\n",
      " [ 126  930]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and Character stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c878d",
   "metadata": {},
   "source": [
    "###### 4.3.4. Sentence-Level stylometry features (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "753d778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = all_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 26:33] #Sentence-Level stylometry features \n",
    "y = all_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "504febd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and Sentence stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.5857\n",
      "precision: 0.5680\n",
      "recall: 0.6127\n",
      "f1: 0.5895\n",
      "Confusion Matrix:\n",
      "[[627 492]\n",
      " [409 647]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9232\n",
      "precision: 0.9174\n",
      "recall: 0.9252\n",
      "f1: 0.9213\n",
      "Confusion Matrix:\n",
      "[[1031   88]\n",
      " [  79  977]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9490\n",
      "precision: 0.9548\n",
      "recall: 0.9394\n",
      "f1: 0.9470\n",
      "Confusion Matrix:\n",
      "[[1072   47]\n",
      " [  64  992]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7232\n",
      "precision: 0.8429\n",
      "recall: 0.5284\n",
      "f1: 0.6496\n",
      "Confusion Matrix:\n",
      "[[1015  104]\n",
      " [ 498  558]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8924\n",
      "precision: 0.8750\n",
      "recall: 0.9081\n",
      "f1: 0.8913\n",
      "Confusion Matrix:\n",
      "[[982 137]\n",
      " [ 97 959]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.5710\n",
      "precision: 0.6253\n",
      "recall: 0.2907\n",
      "f1: 0.3969\n",
      "Confusion Matrix:\n",
      "[[935 184]\n",
      " [749 307]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.5821\n",
      "precision: 0.5637\n",
      "recall: 0.6155\n",
      "f1: 0.5885\n",
      "Confusion Matrix:\n",
      "[[616 503]\n",
      " [406 650]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.7195\n",
      "precision: 0.6652\n",
      "recall: 0.8504\n",
      "f1: 0.7465\n",
      "Confusion Matrix:\n",
      "[[667 452]\n",
      " [158 898]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.8625\n",
      "precision: 0.8714\n",
      "recall: 0.8409\n",
      "f1: 0.8559\n",
      "Confusion Matrix:\n",
      "[[988 131]\n",
      " [168 888]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.8966\n",
      "precision: 0.9270\n",
      "recall: 0.8542\n",
      "f1: 0.8891\n",
      "Confusion Matrix:\n",
      "[[1048   71]\n",
      " [ 154  902]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and Sentence stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f7a1cd",
   "metadata": {},
   "source": [
    "###### 4.3.5. Para-Level stylometry features, Document-Level stylometry features, Textual Entropy stylometry features (10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5007b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing\n",
    "\n",
    "X = sen_level_Dataset_features.drop(['Label'], axis=1)  # Features\n",
    "X = X.iloc[:, 33:]\n",
    "y = sen_level_Dataset_features['Label']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "93630340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and Para-Level , Document-Level, Textual Entropy Stylometry features\n",
      "\u001b[0m\n",
      "\u001b[4m1: Classifier Name: LogisticRegression\u001b[0m\n",
      "Accuracy: 0.6792\n",
      "precision: 0.7627\n",
      "recall: 0.5238\n",
      "f1: 0.6211\n",
      "Confusion Matrix:\n",
      "[[453  89]\n",
      " [260 286]]\n",
      "\n",
      "\u001b[4m2: Classifier Name: DecisionTreeClassifier\u001b[0m\n",
      "Accuracy: 0.9540\n",
      "precision: 0.9397\n",
      "recall: 0.9707\n",
      "f1: 0.9550\n",
      "Confusion Matrix:\n",
      "[[508  34]\n",
      " [ 16 530]]\n",
      "\n",
      "\u001b[4m3: Classifier Name: RandomForestClassifier\u001b[0m\n",
      "Accuracy: 0.9862\n",
      "precision: 0.9819\n",
      "recall: 0.9908\n",
      "f1: 0.9863\n",
      "Confusion Matrix:\n",
      "[[532  10]\n",
      " [  5 541]]\n",
      "\n",
      "\u001b[4m4: Classifier Name: SVC\u001b[0m\n",
      "Accuracy: 0.7619\n",
      "precision: 0.8345\n",
      "recall: 0.6557\n",
      "f1: 0.7344\n",
      "Confusion Matrix:\n",
      "[[471  71]\n",
      " [188 358]]\n",
      "\n",
      "\u001b[4m5: Classifier Name: KNeighborsClassifier\u001b[0m\n",
      "Accuracy: 0.8796\n",
      "precision: 0.8571\n",
      "recall: 0.9121\n",
      "f1: 0.8838\n",
      "Confusion Matrix:\n",
      "[[459  83]\n",
      " [ 48 498]]\n",
      "\n",
      "\u001b[4m6: Classifier Name: GaussianNB\u001b[0m\n",
      "Accuracy: 0.6461\n",
      "precision: 0.8286\n",
      "recall: 0.3718\n",
      "f1: 0.5133\n",
      "Confusion Matrix:\n",
      "[[500  42]\n",
      " [343 203]]\n",
      "\n",
      "\u001b[4m7: Classifier Name: LinearDiscriminantAnalysis\u001b[0m\n",
      "Accuracy: 0.7316\n",
      "precision: 0.7810\n",
      "recall: 0.6465\n",
      "f1: 0.7074\n",
      "Confusion Matrix:\n",
      "[[443  99]\n",
      " [193 353]]\n",
      "\n",
      "\u001b[4m8: Classifier Name: MLPClassifier\u001b[0m\n",
      "Accuracy: 0.7528\n",
      "precision: 0.6965\n",
      "recall: 0.8993\n",
      "f1: 0.7850\n",
      "Confusion Matrix:\n",
      "[[328 214]\n",
      " [ 55 491]]\n",
      "\n",
      "\u001b[4m9: Classifier Name: GradientBoostingClassifier\u001b[0m\n",
      "Accuracy: 0.9347\n",
      "precision: 0.9310\n",
      "recall: 0.9396\n",
      "f1: 0.9353\n",
      "Confusion Matrix:\n",
      "[[504  38]\n",
      " [ 33 513]]\n",
      "\n",
      "\u001b[4m10: Classifier Name: VotingClassifier\u001b[0m\n",
      "Accuracy: 0.8566\n",
      "precision: 0.9472\n",
      "recall: 0.7564\n",
      "f1: 0.8411\n",
      "Confusion Matrix:\n",
      "[[519  23]\n",
      " [133 413]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert X_train and X_test to NumPy arrays\n",
    "X_train_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "\n",
    "# Ensure the arrays are contiguous\n",
    "X_train_np = np.ascontiguousarray(X_train_np)\n",
    "X_test_np = np.ascontiguousarray(X_test_np)\n",
    "\n",
    "\n",
    "# Initialize classifiers\n",
    "logreg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "mlp = MLPClassifier(max_iter=1000)  # Adjust max_iter based on convergence\n",
    "xgb = GradientBoostingClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('logreg', logreg),\n",
    "    ('dtree', dtree),\n",
    "    ('rf', rf),\n",
    "    ('svm', svm),\n",
    "    ('knn', knn),\n",
    "    ('nb', nb),\n",
    "    ('lda', lda),\n",
    "    ('mlp', mlp),\n",
    "    ('xgb', xgb)\n",
    "], voting='hard')\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "classifiers = [logreg, dtree, rf, svm, knn, nb, lda, mlp, xgb, voting_clf]\n",
    "print('\\033[1;4mApply Machine Learning Algorithms on 3. Sen+Para-Level Dataset and Para-Level , Document-Level, Textual Entropy Stylometry features\\n\\033[0m')\n",
    "\n",
    "for i,clf in enumerate(classifiers):\n",
    "    clf.fit(X_train_np, y_train)\n",
    "    y_pred = clf.predict(X_test_np)\n",
    "    print(f\"\\033[4m{i+1}: Classifier Name: {clf.__class__.__name__}\\033[0m\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\\nprecision: {precision_score(y_test,y_pred):.4f}\\nrecall: {recall_score(y_test,y_pred):.4f}\\nf1: {f1_score(y_test,y_pred):.4f}\\nConfusion Matrix:\\n{confusion_matrix(y_test,y_pred)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
